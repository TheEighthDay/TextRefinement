# -*- coding: utf-8 -*-
# liyan26@kuaishou.com 李岩 @2021-11-10 11:35:13
# Last Change:  2022-01-06 21:22:23


import os
import random
from bs4 import BeautifulSoup
import argparse
from datetime import datetime, timedelta


class GenHtml(object):
    '''
    save_root: dir to save html
    url_file: generated by gen_url.py
    '''
    def __init__(self, save_root):
        self.max_rows = 1000
        if not os.path.exists(save_root):
            os.makedirs(save_root)
        self.save_root = save_root

    def gen_html(self, url_file, output_name):
        # import pdb; pdb.set_trace()
        # url_file = os.path.join(self.save_root, url_file)

        lines = open(url_file).readlines()
        # random.shuffle(lines)
        # lines = sorted(lines, key=lambda v: -len(v))
        cnt = 0
        col = 0
        soup = BeautifulSoup(open('./inputs/template.html'), 'lxml')
        content_tr = None
        description_tr = None
        for line_idx, line in enumerate(lines):

            flag = (1 <= (line_idx+1) <= self.max_rows)
            if not flag:
                continue

            # if col % 2 == 0:
                # content_tr = soup.new_tag('tr')
                # description_tr = soup.new_tag('tr')
            content_tr = soup.new_tag('tr')
            description_tr = soup.new_tag('tr')
            content_td = soup.new_tag('td')
            description_td = soup.new_tag('td')
            elements = line.rstrip().split("\x01")  # <$> separate different elements

            for element in elements:
                # import pdb; pdb.set_trace()
                try:
                    url, title = element.split('\x02')  # ";" separate url and title
                    # url = url.replace(',', '%2c')
                    title_list = title.split('\x03')
                    # import pdb; pdb.set_trace()
                except:
                    print("--->", line_idx, element)
                    # return
                element_th = soup.new_tag('th')
                element_id_th = soup.new_tag('th')
                if url.endswith(('.png', '.jpg', '.jpeg', '.bmp')):
                    element_embeded = soup.new_tag('img', src=url, width='400')
                    element_th.append(element_embeded)
                    for _subtitle in title_list:
                        _br = soup.new_tag('div')
                        _br.string = _subtitle
                        element_id_th.append(_br)
                else:
                    element_embeded = soup.new_tag('video', controls='controls', src=url, width='400')
                    element_th.append(element_embeded)
                    element_id_th.string = title
                content_td.append(element_th)
                description_td.append(element_id_th)
                col += 1
                content_tr.append(content_td)
                description_tr.append(description_td)
            soup.body.table.append(content_tr)
            soup.body.table.append(description_tr)

        if soup is not None:
            with open('{}/{}'.format(self.save_root, output_name), 'w') as fid:
                fid.write(str(soup))


def argu_parse():
    parser = argparse.ArgumentParser()
    parser.add_argument('--url_file', type=str, default='photoidUrl.txt')
    parser.add_argument('--save_root', type=str, default='./html_output')
    parser.add_argument('--outp_name', type=str, default='result.html')
    args = parser.parse_args()
    return args


def main():
    args = argu_parse()
    html_generator = GenHtml(args.save_root)
    html_generator.gen_html(args.url_file, args.outp_name)
    return

if __name__ == '__main__':
    main()
